% Generated by roxygen2 (4.1.0): do not edit by hand
% Please edit documentation in R/S3functions.R
\name{learn.file}
\alias{learn.file}
\title{Run SparkBeyond feature enrichment and learning process.}
\usage{
learn.file(projectName = "temp", trainDataFilename, target,
  testDataFilename = NA, trainTestSplitRatio = 0.8, weightColumn = NA,
  maxDepth = 2, algorithmsWhiteList = NA, functionsWhiteList = NA,
  functionsBlackList = NA, useGraph = FALSE, maxFeaturesCount = 300,
  columnSubsetSize = 1, customColumnSubsets = NA,
  evaluationMetric = "PREC", scoreOnTestSet = FALSE, crossValidation = 5,
  allocatedMemoryMB = 1000, maxCollectionSize = 80000,
  weightByClass = FALSE, produceFeatureClusteringReport = FALSE,
  fileEncoding = NA, runBlocking = TRUE, verbose = FALSE)
}
\arguments{
\item{target}{String of the column name of in the training file that contains the target of the prediction.}

\item{projectName:}{Optional string of the session name. Setting a session name is highly recommended. "temp" by default.}

\item{trainDataFilename:}{Define the path to the training data to use.}

\item{testDataFilename:}{Optional. define a the path to the test data to use. NA by default.}

\item{trainTestSplitRatio:}{Optional. Double value in [0,1] to split the train file data in order to keep some data for test. 0.8 by default. Ignored if test filename was provided.}

\item{weightColumn:}{Optional. String of the name of of one of the column that indicate a weighting that is assigned to each example. NA by default.}

\item{maxDepth:}{Optional. Integer < 8 which represent the maximum number of transformations allowed during the feature search phase. Increasing this value should be considered with cautious as the feature search phase is exponential. 2 by default.}

\item{algorithmsWhiteList:}{Optional. A list of strings that represents the set of algorithms to run. NA by default}

\item{functionsWhiteList:}{Optional. A list of strings that represents a set of functions that will be used to guide the feature search. NA by default.}

\item{functionsBlackList:}{Optional. A list of strings that represents a set of function that will be excluded from the feature search. NA by default.}

\item{useGraph:}{Optional. A boolean indicating whether the knowledge graph should be used. FALSE by default.}

\item{maxFeaturesCount:}{Optional. An integer of how many features should be created by the SB engine. 300 by default.}

\item{columnSubsetSize:}{Optional. An integer denoting whether sets of columns should be looked at together. 1 by default.}

\item{customColumnSubsets:}{Optional. A List of lists containing specific column subsets to examine. NA by default.}

\item{evaluationMetric:}{Optional. A string representing the evaluation metric. Should be either "AUC", "PREC", or "RMSE". "PREC" by default.}

\item{scoreOnTestSet:}{Optional. A boolean representing whether scoring should be provided for the test set. FALSE by default.}

\item{crossValidation:}{Optional. Integer value representing how many cross validation splits should be used. 5 by default.}

\item{allocatedMemoryMB:}{Optional. Integer value representing how to chunk the memory during feature search . 1000MB by default.}

\item{maxCollectionSize:}{Optional. Integer  value repsenting what is the maximum cardinality allowed for a transformation during feature search. 80K by default.}

\item{weightByClass:}{Adds a weight column with values inverse proportional to the frequency of the class. FALSE by default.}

\item{produceFeatureClusteringReport:}{An indicator to produce feature cluster visualization. FALSE by default.}

\item{fileEncoding:}{Optional. NA by default. Options are: "ISO-8859-1", "UTF-8", "US-ASCII".}
}
\value{
Session object that encapsulates the model.
}
\description{
Run SparkBeyond feature enrichment and learning process.
}
\examples{
#session = learn("titanic", titanic_file_path, target = "survived", algorithmsWhiteList = list("RRandomForest"), runBlocking = TRUE)
}

