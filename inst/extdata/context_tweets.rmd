---
output:
  knitrBootstrap::bootstrap_document:
    theme.chooser: TRUE
    highlight.chooser: TRUE
---

<!--
%\VignetteEngine{knitr::rmarkdown}
%\VignetteIndexEntry{context_tweets}
%\VignetteDepends{xtable}
-->

##Text analysis - tweets sentiment##

<img src="http://s3.amazonaws.com/public-sparkbeyond/images/sentiment.jpg" width="462" height="260">
<br>

###Internal text functions###

<br>

####Overview####

Goal: Identify sentiment in twitter tweets. The sentiment dataset contains a column with a tweet and a setiment target (-1 or 1).
<br>

####Training data####
```{r context_tweets_0, eval=TRUE, results='asis', cache=TRUE}
tweets = getData("tweets_sentiment")
print(xtable(head(tweets,n=5)), type='html', comment=F)
```

####Pipeline####

```{r context_tweets_1, eval=TRUE, message=FALSE, results='hide', cache=TRUE}
SentimentModel = learn(
	projectName="tweets",
	trainData=tweets,
	target="sentiment",
	featureGeneration = featureGenerationControl(maxFeaturesCount = list(40))
)
```
<br>

####Top features####

The top feature is a textSentimentScore which is automatically computed.

```{r context_tweets_2, eval=TRUE, results='asis', cache=TRUE}
print(xtable(SentimentModel$features()[1:5,c("feature", "RIG")]), type='html', comment=F)
```

####Evaluation####

```{r context_tweets_3, eval=TRUE, echo=TRUE, cache=TRUE}
SentimentModelEval = SentimentModel$evaluate()
```
<br>

###Terms Map context###

<img src="http://s3.amazonaws.com/public-sparkbeyond/images/context1.jpg" width="400" height="324">

<br>

####Overview####

In order to improve performance we can include a custom context Dataset. The sentimentLexicon includes over 6000 single words with a either a positive or negative sentiment. The top features now are actually derived by looking up the values in the lexcion (data_column) and the classificaiton performance is boosted.

####Context data####

```{r context_tweets_4_0, eval=TRUE, results='asis', cache=TRUE}
lexicon = getData("sentiment_lexicon")
print(xtable(head(lexicon, n=5)), type='html', comment=F)
```

####Pipeline####

<br>
Based on the column types in the context data, various context objects can be created. See contextTypesList for complete information on all possible context object types. It is also possible to define the requested context types to be generated explicitly in contextObject. Specifically, in this case we will define a Terms Map context. 
<br>
<br>

```{r context_tweets_4, eval=TRUE, message=FALSE, results='hide', cache=TRUE}
SentimentModelContext = learn(
	projectName = "tweets",
	trainData = tweets,
	target = "sentiment",
	contextDatasets = list(contextObject(data = getData("sentiment_lexicon"), name = "sentiment_lexicon",
		contextTypes = contextTypesList(termsMap = TRUE))), #defining the context type explicity
	featureGeneration = featureGenerationControl(maxFeaturesCount = list(40))
)
```

####Top features####

```{r context_tweets_5, eval=TRUE, results='asis', cache=TRUE}
print(xtable(SentimentModelContext$features()[1:5,c("feature", "RIG")]), type='html', comment=F) 
```

####Evaluation####
```{r context_tweets_7, eval=TRUE, echo=TRUE, cache=TRUE}
SentimentContextEval = SentimentModelContext$evaluate()
```

<br>
<br>

###Inverted Index context###

####Overview####
<br>
In this example we will see how to add an Inverted Index context. Specifically, this will allow us to use similar textual instances to augment the feature search, in a KNN-fashion. In this example, during the training, only the context information of the train data will be made available for feature search purposes. However, during prediction, the context information of both the train data and the test data can be made available.
<br>
<br>

####Pipeline####

We will first split the data into train and test data using the trainTestSplit function.

```{r context_tweets_8, eval=TRUE, message=FALSE, results='hide', cache=TRUE}
trainTestData=trainTestSplit(tweets,0.5)
SentimentModelContext2 = learn(
	projectName="tweets_semtiment3",
	trainData=trainTestData$train,
	testData =trainTestData$test,
	target="sentiment",
	featureGeneration = featureGenerationControl(maxFeaturesCount = list(40)), 
	contextDatasets = list(contextObject(data = trainTestData$train, name = "tweets_context", 
				contextTypes = contextTypesList(invertedIndex = TRUE))) #defining the context type explicitly
)
```
<br>

####Top features####

```{r context_tweets_9, eval=TRUE, results='asis', cache=TRUE}
print(xtable(SentimentModelContext2$features()[1:5,c("feature", "RIG")]), type='html', comment=F) 
```

####Evaluation####

During prediction we can match the context objects to the ones used in the train by using the same name.
<br>

```{r context_tweets_10, eval=TRUE, echo=TRUE, , results='hide', cache=TRUE, message=FALSE}
	pred = SentimentModelContext2$predict(data = trainTestData$test, 
				contextDatasets = list(contextObject(data = tweets, name = "tweets_context")))
```
```{r context_tweets_11, eval=TRUE, echo=TRUE, cache=TRUE, message=FALSE}
	length(which(pred$sentiment==pred$sentiment_predicted))/nrow(pred) * 100
```